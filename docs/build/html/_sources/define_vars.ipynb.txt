{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3da12b7",
   "metadata": {},
   "source": [
    "# User Input for a Prometheus Run\n",
    "=================================\n",
    "\n",
    "Please run each code block and follow the instructions.\n",
    "The end result will be a downloadable .csv file with the necessary values.\n",
    "Ensure that you have python and wget installed on your machine before starting.\n",
    "\n",
    "There is an accompanying how-to in the \"Installations\" tab.\n",
    "\n",
    "This notebook will always attempt to grab the most up-to-date model data. If running more a previous day, it will grab the 18Z run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa30f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import xarray as xr\n",
    "import shutil\n",
    "import cfgrib\n",
    "\n",
    "from ipyleaflet import Map, Marker, GeoJSON\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from etl_prometheus_data import download_data, KDTree_interpolate_grib2_to_point, GRID_interpolate_grib2_to_point\n",
    "from file_funcs import set_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the etl_nfdf_polygons.py script to get the NFDF polygons\n",
    "print(\"Note: you only have to run this cell every few hours when new perimeters come in\")\n",
    "%run etl_nfdb_polygons.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e71ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbuchart\\AppData\\Local\\Temp\\ipykernel_37388\\131360457.py:14: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the map to get coordinates\n",
      "Double-click to zoom in or use the zoom controls\n",
      "Your final click is the selected location, ensure that the marker is moved to where you want it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0622f971cd485f94a28c5612eb3dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[56.44313049803843, -106.76174096729078], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3598c0a596ff4d0cbb3746222781f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the GeoJSON file with geopandas\n",
    "gdf = gpd.read_file('Canada_perimeters.geojson')\n",
    "\n",
    "# Ensure CRS is WGS84\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Optionally drop columns you don't need\n",
    "gdf = gdf.drop(columns=['FIRSTDATE', 'LASTDATE', 'CONSIS_ID'])\n",
    "\n",
    "# Convert to GeoJSON dict\n",
    "geojson_data = json.loads(gdf.to_json())\n",
    "\n",
    "# Center the map on the centroid of all polygons\n",
    "center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n",
    "m = Map(center=center, zoom=4)\n",
    "\n",
    "# Add the GeoJSON layer\n",
    "geojson_layer = GeoJSON(\n",
    "    data=geojson_data,\n",
    "    name='NFDB Polygons',\n",
    "    style={\n",
    "        'color': 'red',\n",
    "        'weight': 1,\n",
    "        'fillColor': 'orange',\n",
    "        'fillOpacity': 0.6\n",
    "    }\n",
    ")\n",
    "m.add_layer(geojson_layer)\n",
    "\n",
    "# add marker that will be updated on click\n",
    "marker = Marker(location=center)    \n",
    "m.add_layer(marker)\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def handle_map_click(**kwargs):\n",
    "    if kwargs.get('type') == 'click':\n",
    "        latlon = kwargs.get('coordinates')\n",
    "        marker.location = latlon\n",
    "        with out:\n",
    "            print(f\"Clicked location: {latlon}\")\n",
    "\n",
    "m.on_interaction(handle_map_click)\n",
    "\n",
    "print(\"Click on the map to get coordinates\")\n",
    "print(\"Double-click to zoom in or use the zoom controls\")\n",
    "print(\"Your final click is the selected location, ensure that the marker is moved to where you want it\")\n",
    "display(m, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a5f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final coordinates you have selected are: [62.05448866672659, -117.15305942475538]\n"
     ]
    }
   ],
   "source": [
    "coords = marker.location\n",
    "print(f\"The final coordinates you have selected are: {coords}\")\n",
    "\n",
    "# save the map to an HTML file\n",
    "m.save('nfdb_polygons_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19646c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires your initial forecast hour in UTC, and your current timezone offset from UTC..\n",
      "please\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c9bc54851945eb8c03224ccede3dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('rdps', 'hrdps'), value='rdps')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dca25404e784fbb89a977b59aaa947f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model Initialization Time:', index=4, options=('00', '06', '12', '18', 'auto'), style=De…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55392f061cd145dab6bdf4888e38cec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=2025, continuous_update=False, description='Year:', max=2025, min=2020)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19989ff7d91b4262b2b833731e8f51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Month:', max=12, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74590f1b8ae44a4a78395191a061b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Day:', max=31, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbfc80757f34cebb877803e373b2c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description='Hour (UTC):', max=23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a873b8ac5e4398bf3c649d67490dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=5, continuous_update=False, description='Forecast Length (hours):', max=5, min=1, style=Slider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f168cb69ccd443048e34b90ce6ccd08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=6, continuous_update=False, description='Number of hours behind UTC:', max=14, style=SliderSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once you are happy with your selections\n",
      "Move to the next cell to begin gathering files and interpolating\n",
      "Note that the MSC Datamart only has data from the previous 30 days\n"
     ]
    }
   ],
   "source": [
    "# now select model and dates to download ECCC data\n",
    "from IPython.display import display\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=['rdps', 'hrdps'],\n",
    "    value='rdps',\n",
    "    description='Model:',\n",
    ")\n",
    "\n",
    "model_run = widgets.Dropdown(\n",
    "    options=['00', '06', '12', '18', \"auto\"],\n",
    "    value='auto',\n",
    "    description='Model Initialization Time:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "current_year = datetime.now().year\n",
    "year_slider = widgets.IntSlider(\n",
    "    value=int(current_year),\n",
    "    min=2020,\n",
    "    max = int(current_year),\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "month_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Month:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "day_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1, \n",
    "    max=31,\n",
    "    step=1,\n",
    "    description='Day:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "hour_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, \n",
    "    max=23,\n",
    "    step=1,\n",
    "    description='Hour (UTC):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "forecast_slider = widgets.IntSlider(\n",
    "    value=48,\n",
    "    min=24,  # 24\n",
    "    max=72,  # 72\n",
    "    step=6,  # 6\n",
    "    description='Forecast Length (hours):',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "time_offset = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=0,\n",
    "    max=14,\n",
    "    step=1,\n",
    "    description='Number of hours behind UTC:',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Requires your initial forecast hour in UTC, and your current timezone offset from UTC..\")\n",
    "print(\"please\")\n",
    "\n",
    "display(model_dropdown, model_run, year_slider, month_slider, day_slider, hour_slider, forecast_slider, time_offset)\n",
    "\n",
    "print(\"Once you are happy with your selections\")\n",
    "print(\"Move to the next cell to begin gathering files and interpolating\")\n",
    "\n",
    "print(\"Note that the MSC Datamart only has data from the previous 30 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87948fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are running a very up-to-date model and this breaks...\n",
      "The latest model data might not be in, try going one model run previous\n",
      "Selected Model: rdps\n",
      "Selected Model Run: auto\n",
      "Selected Date: 2025-08-14--09\n",
      "Forecast Length: 2 hours\n",
      "The model starts at \n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2\n"
     ]
    }
   ],
   "source": [
    "print(\"If you are running a very up-to-date model and this breaks...\")\n",
    "print(\"The latest model data might not be in, try going one model run previous\")\n",
    "model_files = set_filenames(model_dropdown.value, model_run.value, \n",
    "                            year_slider.value, month_slider.value, \n",
    "                            day_slider.value, hour_slider.value, \n",
    "                            forecast_slider.value, \n",
    "                            time_offset.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d706cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDTree finds the nearest neighbour on the model grid - very fast ~3mins\n",
      "Linear interpolation is much slower, a 30hr forecast will take ~30mins to process the data\n",
      "In my experience the absolute difference between methods is ~0.4degC for temp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092920aff46547968cd4cbe4dd7e5f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Interpolation Method:', options=('KDTree', 'Linear'), style=DescriptionStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine what kind of interpolation do you want to do\n",
    "interp_dropdown = widgets.Dropdown(\n",
    "    options=['KDTree', 'Linear'],\n",
    "    value='KDTree',\n",
    "    description='Interpolation Method:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "print(\"KDTree finds the nearest neighbour on the model grid - very fast ~3mins\")\n",
    "print(\"Linear interpolation is much slower, a 30hr forecast will take ~30mins to process the data\")\n",
    "print(\"In my experience the absolute difference between methods is ~0.4degC for temp\")\n",
    "\n",
    "display(interp_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9cb06f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       HOURLY  HOUR TEMP   RH   WD   WS PRECIP       temp_datetime\n",
      "0  14/08/2025     3  NaN  NaN  NaN  NaN    NaN 2025-08-14 03:00:00\n",
      "1  14/08/2025     4  NaN  NaN  NaN  NaN    NaN 2025-08-14 04:00:00\n"
     ]
    }
   ],
   "source": [
    "# make the dataframe to store the interpolate variables \n",
    "# following the example provided at: \n",
    "# https://spotwx.com/products/grib_index.php?model=hrdps_1km_west&lat=50.80476&lon=-116.82362&tz=America/Edmonton&display=table_prometheus\n",
    "# open the prometheus json file to help with creating the \n",
    "with open('prometheus_vars.json', 'r') as f:\n",
    "            prometheus_vars = json.load(f)\n",
    "\n",
    "all_final_vars = prometheus_vars[\"required_vars\"]\n",
    "dynamic_vars = prometheus_vars[\"eccc_equivalents\"]\n",
    "\n",
    "output_df = pd.DataFrame(columns=all_final_vars.values())\n",
    "\n",
    "# now deal with the indexes - fill the HOURLY and HOUR columns\n",
    "times = model_files[\"datetime\"].unique()\n",
    "\n",
    "output_df[\"HOURLY\"] = times\n",
    "output_df[\"HOUR\"] = times\n",
    "output_df[\"temp_datetime\"] = times\n",
    "\n",
    "def just_date(x):\n",
    "    # change datetime object to dd/mm/yy format\n",
    "    return x.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "def just_hour(x):\n",
    "    # grab just the hour of the datetime object\n",
    "    return x.hour\n",
    "\n",
    "output_df[\"HOURLY\"] = output_df[\"HOURLY\"].apply(just_date)\n",
    "output_df[\"HOUR\"] = output_df[\"HOUR\"].apply(just_hour)\n",
    "\n",
    "print(output_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11441269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 t2m 282.83365\n",
      "5\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 t2m 282.4765\n",
      "1\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 r2 78.413635\n",
      "6\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 r2 79.94868\n",
      "3\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 wdir10 187.0\n",
      "8\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 wdir10 163.1\n",
      "2\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 si10 0.97\n",
      "7\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 si10 0.96\n",
      "4\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 unknown 0.0\n",
      "9\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 unknown 0.0\n",
      "       HOURLY  HOUR        TEMP         RH          WD    WS PRECIP\n",
      "0  14/08/2025     3  282.829987  78.410004       187.0  0.97    0.0\n",
      "1  14/08/2025     4  282.480011  79.949997  163.100006  0.96    0.0\n"
     ]
    }
   ],
   "source": [
    "# loop through the model_files DataFrame and download each file\n",
    "new_row = {}\n",
    "looptime = datetime.now()  # hacky workaround for my dataframe population, im not sorry, just lazy\n",
    "\n",
    "# loop through the required vars\n",
    "for ii in range(len(dynamic_vars.keys())):\n",
    "    ec_var = list(dynamic_vars.keys())[ii]\n",
    "    prom_var = list(dynamic_vars.values())[ii]\n",
    "\n",
    "    # just grab the dataframe for one variable then populate that column of the final \n",
    "    # prometheus dataframe - I dont want to hear it...\n",
    "    spec_model_files = model_files.loc[model_files[\"variable\"] == ec_var]\n",
    "\n",
    "    for index, row in spec_model_files.iterrows():\n",
    "        output_file = row['file']\n",
    "        file_url = row['full_path']\n",
    "        timestamp = row[\"datetime\"]\n",
    "        var = row[\"variable\"]\n",
    "\n",
    "        print(index)\n",
    "\n",
    "        print(file_url, output_file)\n",
    "        download_data(file_url, output_file)\n",
    "\n",
    "        if interp_dropdown.value == interp_dropdown.options[0]:\n",
    "        \n",
    "            value = KDTree_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        elif interp_dropdown == interp_dropdown.options[1]:\n",
    "\n",
    "            value = GRID_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        #print(f\"The variable is: {var} and  has a value of {value}\")\n",
    "\n",
    "        print(timestamp, var, value)\n",
    "        output_df.loc[output_df[\"temp_datetime\"] == timestamp, prom_var] = np.round(np.float32(value), 2)\n",
    "\n",
    "init = output_df[\"temp_datetime\"][0].strftime(\"%Y_%m_%d_%h\")\n",
    "output_df = output_df.drop(columns=['temp_datetime'])\n",
    "print(output_df)\n",
    "\n",
    "output_df.to_csv(f\"./output/{init}_prometheus_data_{str(forecast_slider.value)}\")\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
