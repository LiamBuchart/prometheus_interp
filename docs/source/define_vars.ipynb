{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3da12b7",
   "metadata": {},
   "source": [
    "# User Input for a Prometheus Run\n",
    "=================================\n",
    "\n",
    "Please run each code block and follow the instructions.\n",
    "The end result will be a downloadable .csv file with the necessary values.\n",
    "Ensure that you have python and wget installed on your machine before starting.\n",
    "\n",
    "There is an accompanying how-to in the \"Installations\" tab.\n",
    "\n",
    "This notebook will always attempt to grab the most up-to-date model data. If running more a previous day, it will grab the 18Z run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa30f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import xarray as xr\n",
    "import shutil\n",
    "import cfgrib\n",
    "\n",
    "from ipyleaflet import Map, Marker, GeoJSON\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from etl_prometheus_data import download_data, KDTree_interpolate_grib2_to_point, GRID_interpolate_grib2_to_point\n",
    "from file_funcs import set_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the etl_nfdf_polygons.py script to get the NFDF polygons\n",
    "print(\"Note: you only have to run this cell every few hours when new perimeters come in\")\n",
    "%run etl_nfdb_polygons.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e71ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbuchart\\AppData\\Local\\Temp\\ipykernel_37388\\131360457.py:14: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the map to get coordinates\n",
      "Double-click to zoom in or use the zoom controls\n",
      "Your final click is the selected location, ensure that the marker is moved to where you want it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0622f971cd485f94a28c5612eb3dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[56.44313049803843, -106.76174096729078], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3598c0a596ff4d0cbb3746222781f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the GeoJSON file with geopandas\n",
    "gdf = gpd.read_file('Canada_perimeters.geojson')\n",
    "\n",
    "# Ensure CRS is WGS84\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Optionally drop columns you don't need\n",
    "gdf = gdf.drop(columns=['FIRSTDATE', 'LASTDATE', 'CONSIS_ID'])\n",
    "\n",
    "# Convert to GeoJSON dict\n",
    "geojson_data = json.loads(gdf.to_json())\n",
    "\n",
    "# Center the map on the centroid of all polygons\n",
    "center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n",
    "m = Map(center=center, zoom=4)\n",
    "\n",
    "# Add the GeoJSON layer\n",
    "geojson_layer = GeoJSON(\n",
    "    data=geojson_data,\n",
    "    name='NFDB Polygons',\n",
    "    style={\n",
    "        'color': 'red',\n",
    "        'weight': 1,\n",
    "        'fillColor': 'orange',\n",
    "        'fillOpacity': 0.6\n",
    "    }\n",
    ")\n",
    "m.add_layer(geojson_layer)\n",
    "\n",
    "# add marker that will be updated on click\n",
    "marker = Marker(location=center)    \n",
    "m.add_layer(marker)\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def handle_map_click(**kwargs):\n",
    "    if kwargs.get('type') == 'click':\n",
    "        latlon = kwargs.get('coordinates')\n",
    "        marker.location = latlon\n",
    "        with out:\n",
    "            print(f\"Clicked location: {latlon}\")\n",
    "\n",
    "m.on_interaction(handle_map_click)\n",
    "\n",
    "print(\"Click on the map to get coordinates\")\n",
    "print(\"Double-click to zoom in or use the zoom controls\")\n",
    "print(\"Your final click is the selected location, ensure that the marker is moved to where you want it\")\n",
    "display(m, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a5f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final coordinates you have selected are: [62.05448866672659, -117.15305942475538]\n"
     ]
    }
   ],
   "source": [
    "coords = marker.location\n",
    "print(f\"The final coordinates you have selected are: {coords}\")\n",
    "\n",
    "# save the map to an HTML file\n",
    "m.save('nfdb_polygons_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19646c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires your initial forecast hour in UTC, and your current timezone offset from UTC..\n",
      "please\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c9bc54851945eb8c03224ccede3dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('rdps', 'hrdps'), value='rdps')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dca25404e784fbb89a977b59aaa947f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model Initialization Time:', index=4, options=('00', '06', '12', '18', 'auto'), style=De…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55392f061cd145dab6bdf4888e38cec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=2025, continuous_update=False, description='Year:', max=2025, min=2020)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19989ff7d91b4262b2b833731e8f51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Month:', max=12, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74590f1b8ae44a4a78395191a061b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Day:', max=31, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbfc80757f34cebb877803e373b2c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description='Hour (UTC):', max=23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a873b8ac5e4398bf3c649d67490dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=5, continuous_update=False, description='Forecast Length (hours):', max=5, min=1, style=Slider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f168cb69ccd443048e34b90ce6ccd08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=6, continuous_update=False, description='Number of hours behind UTC:', max=14, style=SliderSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once you are happy with your selections\n",
      "Move to the next cell to begin gathering files and interpolating\n",
      "Note that the MSC Datamart only has data from the previous 30 days\n"
     ]
    }
   ],
   "source": [
    "# now select model and dates to download ECCC data\n",
    "from IPython.display import display\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=['rdps', 'hrdps'],\n",
    "    value='rdps',\n",
    "    description='Model:',\n",
    ")\n",
    "\n",
    "model_run = widgets.Dropdown(\n",
    "    options=['00', '06', '12', '18', \"auto\"],\n",
    "    value='auto',\n",
    "    description='Model Initialization Time:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "current_year = datetime.now().year\n",
    "year_slider = widgets.IntSlider(\n",
    "    value=int(current_year),\n",
    "    min=2020,\n",
    "    max = int(current_year),\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "month_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Month:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "day_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1, \n",
    "    max=31,\n",
    "    step=1,\n",
    "    description='Day:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "hour_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, \n",
    "    max=23,\n",
    "    step=1,\n",
    "    description='Hour (UTC):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "forecast_slider = widgets.IntSlider(\n",
    "    value=48,\n",
    "    min=1,  # 24\n",
    "    max=5,  # 72\n",
    "    step=1,  # 6\n",
    "    description='Forecast Length (hours):',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "time_offset = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=0,\n",
    "    max=14,\n",
    "    step=1,\n",
    "    description='Number of hours behind UTC:',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Requires your initial forecast hour in UTC, and your current timezone offset from UTC..\")\n",
    "print(\"please\")\n",
    "\n",
    "display(model_dropdown, model_run, year_slider, month_slider, day_slider, hour_slider, forecast_slider, time_offset)\n",
    "\n",
    "print(\"Once you are happy with your selections\")\n",
    "print(\"Move to the next cell to begin gathering files and interpolating\")\n",
    "\n",
    "print(\"Note that the MSC Datamart only has data from the previous 30 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87948fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are running a very up-to-date model and this breaks...\n",
      "The latest model data might not be in, try going one model run previous\n",
      "Selected Model: rdps\n",
      "Selected Model Run: auto\n",
      "Selected Date: 2025-08-14--09\n",
      "Forecast Length: 2 hours\n",
      "The model starts at \n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 03:00:00 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "2025-08-14 04:00:00 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2\n"
     ]
    }
   ],
   "source": [
    "print(\"If you are running a very up-to-date model and this breaks...\")\n",
    "print(\"The latest model data might not be in, try going one model run previous\")\n",
    "model_files = set_filenames(model_dropdown.value, model_run.value, \n",
    "                            year_slider.value, month_slider.value, \n",
    "                            day_slider.value, hour_slider.value, \n",
    "                            forecast_slider.value, \n",
    "                            time_offset.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d706cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDTree finds the nearest neighbour on the model grid - very fast ~3mins\n",
      "Linear interpolation is much slower, a 30hr forecast will take ~30mins to process the data\n",
      "In my experience the absolute difference between methods is ~0.4degC for temp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092920aff46547968cd4cbe4dd7e5f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Interpolation Method:', options=('KDTree', 'Linear'), style=DescriptionStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine what kind of interpolation do you want to do\n",
    "interp_dropdown = widgets.Dropdown(\n",
    "    options=['KDTree', 'Linear'],\n",
    "    value='KDTree',\n",
    "    description='Interpolation Method:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "print(\"KDTree finds the nearest neighbour on the model grid - very fast ~3mins\")\n",
    "print(\"Linear interpolation is much slower, a 30hr forecast will take ~30mins to process the data\")\n",
    "print(\"In my experience the absolute difference between methods is ~0.4degC for temp\")\n",
    "\n",
    "display(interp_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9cb06f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       HOURLY  HOUR TEMP   RH   WD   WS PRECIP       temp_datetime\n",
      "0  14/08/2025     3  NaN  NaN  NaN  NaN    NaN 2025-08-14 03:00:00\n",
      "1  14/08/2025     4  NaN  NaN  NaN  NaN    NaN 2025-08-14 04:00:00\n"
     ]
    }
   ],
   "source": [
    "# make the dataframe to store the interpolate variables \n",
    "# following the example provided at: \n",
    "# https://spotwx.com/products/grib_index.php?model=hrdps_1km_west&lat=50.80476&lon=-116.82362&tz=America/Edmonton&display=table_prometheus\n",
    "# open the prometheus json file to help with creating the \n",
    "with open('prometheus_vars.json', 'r') as f:\n",
    "            prometheus_vars = json.load(f)\n",
    "\n",
    "all_final_vars = prometheus_vars[\"required_vars\"]\n",
    "dynamic_vars = prometheus_vars[\"eccc_equivalents\"]\n",
    "\n",
    "output_df = pd.DataFrame(columns=all_final_vars.values())\n",
    "\n",
    "# now deal with the indexes - fill the HOURLY and HOUR columns\n",
    "times = model_files[\"datetime\"].unique()\n",
    "\n",
    "output_df[\"HOURLY\"] = times\n",
    "output_df[\"HOUR\"] = times\n",
    "output_df[\"temp_datetime\"] = times\n",
    "\n",
    "def just_date(x):\n",
    "    # change datetime object to dd/mm/yy format\n",
    "    return x.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "def just_hour(x):\n",
    "    # grab just the hour of the datetime object\n",
    "    return x.hour\n",
    "\n",
    "output_df[\"HOURLY\"] = output_df[\"HOURLY\"].apply(just_date)\n",
    "output_df[\"HOUR\"] = output_df[\"HOUR\"].apply(just_hour)\n",
    "\n",
    "print(output_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11441269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 t2m 282.83365\n",
      "5\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_AirTemp_AGL-2m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 t2m 282.4765\n",
      "1\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 r2 78.413635\n",
      "6\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_RelativeHumidity_AGL-2m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 r2 79.94868\n",
      "3\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 wdir10 187.0\n",
      "8\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindDir_AGL-10m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 wdir10 163.1\n",
      "2\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 si10 0.97\n",
      "7\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_WindSpeed_AGL-10m_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 si10 0.96\n",
      "4\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/003/20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT003H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 03:00:00 unknown 0.0\n",
      "9\n",
      "https://dd.weather.gc.ca/20250814/WXO-DD/model_rdps/10km/06/004/20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2\n",
      "File downloaded successfully: 20250814T06Z_MSC_RDPS_Precip-Accum1h_Sfc_RLatLon0.09_PT004H.grib2, moving to /temp/ ...\n",
      "Commence interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode the variable 'step' into a timedelta64 dtype based on the presence of a timedelta-like 'units' attribute by default. Instead it will rely on the presence of a timedelta64 'dtype' attribute, which is now xarray's default way of encoding timedelta64 values.\n",
      "To continue decoding into a timedelta64 dtype, either set `decode_timedelta=True` when opening this dataset, or add the attribute `dtype='timedelta64[ns]'` to this variable on disk.\n",
      "To opt-in to future behavior, set `decode_timedelta=False`.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 04:00:00 unknown 0.0\n",
      "       HOURLY  HOUR        TEMP         RH          WD    WS PRECIP\n",
      "0  14/08/2025     3  282.829987  78.410004       187.0  0.97    0.0\n",
      "1  14/08/2025     4  282.480011  79.949997  163.100006  0.96    0.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '2025-08-14 03:00:00_prometheus_data_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m output_df = output_df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mtemp_datetime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(output_df)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43moutput_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minit\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_prometheus_data_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mforecast_slider\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lbuchart\\AppData\\Local\\anaconda3\\envs\\prom-env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: '2025-08-14 03:00:00_prometheus_data_2'"
     ]
    }
   ],
   "source": [
    "# loop through the model_files DataFrame and download each file\n",
    "new_row = {}\n",
    "looptime = datetime.now()  # hacky workaround for my dataframe population, im not sorry, just lazy\n",
    "\n",
    "# loop through the required vars\n",
    "for ii in range(len(dynamic_vars.keys())):\n",
    "    ec_var = list(dynamic_vars.keys())[ii]\n",
    "    prom_var = list(dynamic_vars.values())[ii]\n",
    "\n",
    "    # just grab the dataframe for one variable then populate that column of the final \n",
    "    # prometheus dataframe - I dont want to hear it...\n",
    "    spec_model_files = model_files.loc[model_files[\"variable\"] == ec_var]\n",
    "\n",
    "    for index, row in spec_model_files.iterrows():\n",
    "        output_file = row['file']\n",
    "        file_url = row['full_path']\n",
    "        timestamp = row[\"datetime\"]\n",
    "        var = row[\"variable\"]\n",
    "\n",
    "        print(index)\n",
    "\n",
    "        print(file_url, output_file)\n",
    "        download_data(file_url, output_file)\n",
    "\n",
    "        if interp_dropdown.value == interp_dropdown.options[0]:\n",
    "        \n",
    "            value = KDTree_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        elif interp_dropdown == interp_dropdown.options[1]:\n",
    "\n",
    "            value = GRID_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        #print(f\"The variable is: {var} and  has a value of {value}\")\n",
    "\n",
    "        print(timestamp, var, value)\n",
    "        output_df.loc[output_df[\"temp_datetime\"] == timestamp, prom_var] = np.round(np.float32(value), 2)\n",
    "\n",
    "init = output_df[\"temp_datetime\"][0].strftime(\"%Y_%m_%d_%h\")\n",
    "output_df = output_df.drop(columns=['temp_datetime'])\n",
    "print(output_df)\n",
    "\n",
    "output_df.to_csv(f\"./output/{init}_prometheus_data_{str(forecast_slider.value)}\")\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
