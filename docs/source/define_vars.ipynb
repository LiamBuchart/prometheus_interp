{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3da12b7",
   "metadata": {},
   "source": [
    "User Input for a Prometheus Run\n",
    "=================================\n",
    "\n",
    "Please run each code block and follow the instructions.\n",
    "The end result will be a downloadable .csv file with the necessary values.\n",
    "Ensure that you have python installed on your machine before starting.\n",
    "\n",
    "There is an accompanying how-to in the \"Setup\" tab.\n",
    "\n",
    "This notebook will always attempt to grab the most up-to-date model data. If running more a previous day, it will grab the 18Z run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa30f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import xarray as xr\n",
    "import shutil\n",
    "import cfgrib\n",
    "\n",
    "from ipyleaflet import Map, Marker, GeoJSON\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from etl_prometheus_data import download_data, KDTree_interpolate_grib2_to_point, GRID_interpolate_grib2_to_point\n",
    "from file_funcs import set_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095fef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you only have to run this cell every few hours when new perimeters come in\n",
      "Shapefile already exists. Downloading the latest data...\n",
      "Downloaded perimeters.shp\n",
      "Downloaded perimeters.shx\n",
      "Downloaded perimeters.dbf\n",
      "Downloaded perimeters.prj\n"
     ]
    }
   ],
   "source": [
    "# run the etl_nfdf_polygons.py script to get the NFDF polygons\n",
    "print(\"Note: you only have to run this cell every few hours when new perimeters come in\")\n",
    "%run etl_nfdb_polygons.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e71ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbuchart\\AppData\\Local\\Temp\\ipykernel_50248\\131360457.py:14: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the map to get coordinates\n",
      "Double-click to zoom in or use the zoom controls\n",
      "Your final click is the selected location, ensure that the marker is moved to where you want it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea59607c9154b4bac959be99ba7a1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[56.502039594502484, -106.84403165366864], controls=(ZoomControl(options=['position', 'zoom_in_textâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd66b2ab0e144c4a08bb219b7f163ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the GeoJSON file with geopandas\n",
    "gdf = gpd.read_file('Canada_perimeters.geojson')\n",
    "\n",
    "# Ensure CRS is WGS84\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Optionally drop columns you don't need\n",
    "gdf = gdf.drop(columns=['FIRSTDATE', 'LASTDATE', 'CONSIS_ID'])\n",
    "\n",
    "# Convert to GeoJSON dict\n",
    "geojson_data = json.loads(gdf.to_json())\n",
    "\n",
    "# Center the map on the centroid of all polygons\n",
    "center = gdf.geometry.unary_union.centroid.coords[0][::-1]\n",
    "m = Map(center=center, zoom=4)\n",
    "\n",
    "# Add the GeoJSON layer\n",
    "geojson_layer = GeoJSON(\n",
    "    data=geojson_data,\n",
    "    name='NFDB Polygons',\n",
    "    style={\n",
    "        'color': 'red',\n",
    "        'weight': 1,\n",
    "        'fillColor': 'orange',\n",
    "        'fillOpacity': 0.6\n",
    "    }\n",
    ")\n",
    "m.add_layer(geojson_layer)\n",
    "\n",
    "# add marker that will be updated on click\n",
    "marker = Marker(location=center)    \n",
    "m.add_layer(marker)\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def handle_map_click(**kwargs):\n",
    "    if kwargs.get('type') == 'click':\n",
    "        latlon = kwargs.get('coordinates')\n",
    "        marker.location = latlon\n",
    "        with out:\n",
    "            print(f\"Clicked location: {latlon}\")\n",
    "\n",
    "m.on_interaction(handle_map_click)\n",
    "\n",
    "print(\"Click on the map to get coordinates\")\n",
    "print(\"Double-click to zoom in or use the zoom controls\")\n",
    "print(\"Your final click is the selected location, ensure that the marker is moved to where you want it\")\n",
    "display(m, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = marker.location\n",
    "print(f\"The final coordinates you have selected are: {coords}\")\n",
    "\n",
    "# save the map to an HTML file\n",
    "m.save('nfdb_polygons_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19646c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now select model and dates to download ECCC data\n",
    "from IPython.display import display\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=['rdps', 'hrdps'],\n",
    "    value='rdps',\n",
    "    description='Model:',\n",
    ")\n",
    "\n",
    "model_run = widgets.Dropdown(\n",
    "    options=['00', '06', '12', '18', \"auto\"],\n",
    "    value='auto',\n",
    "    description='Model Initialization Time:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "current_year = datetime.now().year\n",
    "year_slider = widgets.IntSlider(\n",
    "    value=int(current_year),\n",
    "    min=2020,\n",
    "    max = int(current_year),\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "month_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Month:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "day_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1, \n",
    "    max=31,\n",
    "    step=1,\n",
    "    description='Day:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "hour_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, \n",
    "    max=23,\n",
    "    step=1,\n",
    "    description='Hour (UTC):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "forecast_slider = widgets.IntSlider(\n",
    "    value=48,\n",
    "    min=24,  # 24\n",
    "    max=72,  # 72\n",
    "    step=6,  # 6\n",
    "    description='Forecast Length (hours):',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "time_offset = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=0,\n",
    "    max=14,\n",
    "    step=1,\n",
    "    description='Number of hours behind UTC:',\n",
    "    continuous_update=False,\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Requires your initial forecast hour in UTC, and your current timezone offset from UTC..\")\n",
    "print(\"please\")\n",
    "\n",
    "display(model_dropdown, model_run, year_slider, month_slider, day_slider, hour_slider, forecast_slider, time_offset)\n",
    "\n",
    "print(\"Once you are happy with your selections\")\n",
    "print(\"Move to the next cell to begin gathering files and interpolating\")\n",
    "\n",
    "print(\"Note that the MSC Datamart only has data from the previous 30 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87948fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"If you are running a very up-to-date model and this breaks...\")\n",
    "print(\"The latest model data might not be in, try going one model run previous\")\n",
    "model_files = set_filenames(model_dropdown.value, model_run.value, \n",
    "                            year_slider.value, month_slider.value, \n",
    "                            day_slider.value, hour_slider.value, \n",
    "                            forecast_slider.value, \n",
    "                            time_offset.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine what kind of interpolation do you want to do\n",
    "interp_dropdown = widgets.Dropdown(\n",
    "    options=['KDTree', 'Linear'],\n",
    "    value='KDTree',\n",
    "    description='Interpolation Method:',\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "print(\"KDTree finds the nearest neighbour on the model grid - fast ~10mins\")\n",
    "print(\"Linear interpolation is much slower, a 30hr forecast will take ~45mins to process the data\")\n",
    "print(\"In my experience the absolute difference between methods is ~0.4degC for temp\")\n",
    "\n",
    "display(interp_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe to store the interpolate variables \n",
    "# following the example provided at: \n",
    "# https://spotwx.com/products/grib_index.php?model=hrdps_1km_west&lat=50.80476&lon=-116.82362&tz=America/Edmonton&display=table_prometheus\n",
    "# open the prometheus json file to help with creating the \n",
    "with open('prometheus_vars.json', 'r') as f:\n",
    "            prometheus_vars = json.load(f)\n",
    "\n",
    "all_final_vars = prometheus_vars[\"required_vars\"]\n",
    "dynamic_vars = prometheus_vars[\"eccc_equivalents\"]\n",
    "\n",
    "output_df = pd.DataFrame(columns=all_final_vars.values())\n",
    "\n",
    "# now deal with the indexes - fill the HOURLY and HOUR columns\n",
    "times = model_files[\"datetime\"].unique()\n",
    "\n",
    "output_df[\"HOURLY\"] = times\n",
    "output_df[\"HOUR\"] = times\n",
    "output_df[\"temp_datetime\"] = times\n",
    "\n",
    "def just_date(x):\n",
    "    # change datetime object to dd/mm/yy format\n",
    "    return x.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "def just_hour(x):\n",
    "    # grab just the hour of the datetime object\n",
    "    return x.hour\n",
    "\n",
    "output_df[\"HOURLY\"] = output_df[\"HOURLY\"].apply(just_date)\n",
    "output_df[\"HOUR\"] = output_df[\"HOUR\"].apply(just_hour)\n",
    "\n",
    "print(output_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11441269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the model_files DataFrame and download each file\n",
    "new_row = {}\n",
    "looptime = datetime.now()  # hacky workaround for my dataframe population, im not sorry, just lazy\n",
    "\n",
    "# loop through the required vars\n",
    "for ii in range(len(dynamic_vars.keys())):\n",
    "    ec_var = list(dynamic_vars.keys())[ii]\n",
    "    prom_var = list(dynamic_vars.values())[ii]\n",
    "\n",
    "    # just grab the dataframe for one variable then populate that column of the final \n",
    "    # prometheus dataframe - I dont want to hear it...\n",
    "    spec_model_files = model_files.loc[model_files[\"variable\"] == ec_var]\n",
    "\n",
    "    for index, row in spec_model_files.iterrows():\n",
    "        output_file = row['file']\n",
    "        file_url = row['full_path']\n",
    "        timestamp = row[\"datetime\"]\n",
    "        var = row[\"variable\"]\n",
    "\n",
    "        print(index)\n",
    "\n",
    "        print(file_url, output_file)\n",
    "        download_data(file_url, output_file)\n",
    "\n",
    "        if interp_dropdown.value == interp_dropdown.options[0]:\n",
    "        \n",
    "            value = KDTree_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        elif interp_dropdown == interp_dropdown.options[1]:\n",
    "\n",
    "            value = GRID_interpolate_grib2_to_point(f\"./temp/{output_file}\", var, coords)\n",
    "\n",
    "        print(f\"The variable is: {var} and  has a value of {value}\")\n",
    "\n",
    "        output_df.loc[output_df[\"temp_datetime\"] == timestamp, prom_var] = np.round(np.float32(value), 2)\n",
    "\n",
    "init = output_df[\"temp_datetime\"][0].strftime(\"%Y_%m_%d_%H\") # nice initial value\n",
    "output_df = output_df.drop(columns=['temp_datetime'])  # clean  \n",
    "output_df.reset_index(drop=True, inplace=True)  # nice indexing\n",
    "print(output_df)\n",
    "\n",
    "output_df.to_csv(f\"./output/{init}_prometheus_data_{str(forecast_slider.value)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a931d00-4ba7-4117-b3b2-c2d1c9efd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=center, zoom=4)\n",
    "display(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prom-env]",
   "language": "python",
   "name": "conda-env-prom-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
